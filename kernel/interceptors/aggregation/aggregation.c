#include <linux/kernel.h>
#include <linux/module.h>
#include <linux/netdevice.h>
#include <linux/inetdevice.h>
#include <linux/netfilter.h> 
#include <linux/netfilter_ipv4.h> 
#include <linux/skbuff.h>
#include <linux/ip.h>
#include <linux/udp.h>
#include <linux/in.h>
#include "klist.h"
#include "interceptor.h"
#include "pdu.h"
#include "utils.h"
#include "byte_buffer.h"

static unsigned short aggregate_app_packets = 0;
module_param(aggregate_app_packets, ushort, 0000)
;
MODULE_PARM_DESC(aggregate_app_packets,
    "Aggregate packets generated by the same application. Default is no.");

static unsigned short aggregate_ip_packets = 1;
module_param(aggregate_ip_packets, ushort, 0000)
;
MODULE_PARM_DESC(aggregate_ip_packets, "Aggregate ip packets. Default is yes.");
static unsigned short aggregate_app_packets_buffer_size = 256;
module_param(aggregate_app_packets_buffer_size, ushort, 0000)
;
MODULE_PARM_DESC(
    aggregate_app_packets_buffer_size,
    "Size in bytes of the buffer used to store application generated packets. In other words, how many bytes should be buffered before sending the aggregate packet. Default is 256 Bytes.");

static unsigned short aggregate_ip_buffer_size = 512;
module_param(aggregate_ip_buffer_size, ushort, 0000)
;
MODULE_PARM_DESC(
    aggregate_ip_buffer_size,
    "Size in bytes of the buffer used to store ip packets. In other words, how many bytes should be buffered before sending the aggregate packet. Default is 512 Bytes.");

#define INTERCEPTOR_NAME "aggregation"

interceptor_descriptor agg_desc;

klist *app_buffers = NULL, *ip_buffers = NULL;

static void flush_buffer_app(struct sk_buff* skb, aggregate_buffer* b,
    const struct net_device* out) {
  struct iphdr* iph;
  struct udphdr* udph;
  struct in_device* ipa;
  __tp(pdu)* pdu;
  control_byte *cb;
  __be16 srcport;
  char *begin_of_buffered_data;

  iph = ip_hdr(skb);
  if (iph->protocol == IPPROTO_UDP) {
    udph = (struct udphdr*) (((char*) iph) + (iph->ihl << 2));
    srcport = udph->source;
  } else {
    printk(
        "%s in %s:%d: IP protocol not supported by aggregation interceptor.\n",
        __FUNCTION__, __FILE__, __LINE__);
    return;
  }

  pdu = pdu_skb(skb);
  if (!pdu)
    return;

  //Remove iphdr, udphdr and control byte.
  skb_pull(skb, (iph->ihl << 2) + sizeof(struct udphdr) + sizeof(control_byte));

  //put into skb buffered data
  if (skb_tailroom(skb) < buffer_data_len(b)
    )
    if (pskb_expand_head(skb, 0, buffer_data_len(b) - skb_tailroom(skb),
        GFP_ATOMIC)) {
printk			(KERN_EMERG
					"%s in %s:%d: Failed to expand skb tail. Reseting aggregate buffer anyway\n",
					__FUNCTION__, __FILE__, __LINE__);
			      reset_buffer(b);
      return;
    }
  begin_of_buffered_data = skb_put(skb, buffer_data_len(b));
  memcpy(begin_of_buffered_data, b->head, buffer_data_len(b));
  //--------------------------

  ipa = (struct in_device*) out->ip_ptr;

  if (skb_headroom(skb)
      < sizeof(struct iphdr) + sizeof(struct udphdr) + sizeof(control_byte))
    if (pskb_expand_head(
        skb,
        sizeof(struct iphdr) + sizeof(struct udphdr) + sizeof(control_byte)
            - skb_headroom(skb), 0, GFP_ATOMIC)) {
printk (KERN_EMERG
					"%s in %s:%d: Failed to expand skb head. Reseting aggregate buffer anyway\n",
					__FUNCTION__, __FILE__, __LINE__);
			      reset_buffer(b);
      return;
    }

  cb = (control_byte*) skb_push(skb, sizeof(control_byte));
  udph = (struct udphdr*) skb_push(skb, sizeof(struct udphdr));
  iph = (struct iphdr*) skb_push(skb, sizeof(struct iphdr));

  memset(udph, 0, sizeof(struct udphdr));

  iph->ihl = 5;
  iph->version = 4;
  iph->tos = 0;
  iph->tot_len = htons(
      sizeof(struct iphdr) + sizeof(struct udphdr) + sizeof(control_byte)
          + buffer_data_len(b) + n_pdu_len(pdu));
  iph->id = 0;
  iph->frag_off = 0;
  iph->ttl = 60;
  iph->protocol = IPPROTO_UDP;
  iph->check = 0;
  iph->saddr = ipa->ifa_list->ifa_address;
  iph->daddr = b->id.ip;
  iph->check = csum((uint16_t*) iph, (iph->ihl << 2) >> 1);
  skb_set_network_header(skb, 0);

  udph->len = htons(
      sizeof(control_byte) + n_pdu_len(pdu) + buffer_data_len(b)
          + sizeof(struct udphdr));
  udph->dest = b->id.port;
  udph->source = srcport;
  skb_set_transport_header(skb, sizeof(struct iphdr));

  memset(cb, 0, sizeof(control_byte));
  cb->app_aggregated = 1;

  udph->check = 0;
  reset_buffer(b);
  return;
}

static void flush_buffer_ip(struct sk_buff* skb, aggregate_buffer* b,
    const struct net_device* out) {
  struct iphdr* iph;
  struct udphdr* udph;
  struct in_device* ipa;
  __be16 srcport;
  control_byte* cb;
  uint16_t skb_iph_len;
  char* begin_of_buffered_data;

  iph = ip_hdr(skb);
  if (iph->protocol == IPPROTO_UDP) {
    udph = (struct udphdr*) (((char*) iph) + (iph->ihl << 2));
    srcport = udph->source;
    skb_iph_len = htons(iph->tot_len);
  } else {
    printk("IP protocol not supported by aggregation interceptor.\n");
    return;
  }

  //put into skb buffered data
  if (skb_tailroom(skb) < buffer_data_len(b)
    )
    if (pskb_expand_head(skb, 0, buffer_data_len(b) - skb_tailroom(skb),
        GFP_ATOMIC)) {
      printk(
          "%s in %s:%d: Failed to expand skb tail. Reseting aggregate buffer anyway\n",
          __FUNCTION__, __FILE__, __LINE__);
      reset_buffer(b);
      return;
    }
  begin_of_buffered_data = skb_put(skb, buffer_data_len(b));
  memcpy(begin_of_buffered_data, b->head, buffer_data_len(b));
  //--------------------------

  if (skb_headroom(skb)
      < sizeof(struct iphdr) + sizeof(struct udphdr) + sizeof(control_byte)
          + skb_iph_len)
    if (pskb_expand_head(
        skb,
        sizeof(struct iphdr) + sizeof(struct udphdr) + sizeof(control_byte)
            - skb_headroom(skb), 0, GFP_ATOMIC)) {
      printk(
          "%s:%d: Failed to expand skb head. Reseting aggregate buffer anyway\n",
          __FILE__, __LINE__);
      reset_buffer(b);
      return;
    }

  ipa = (struct in_device*) out->ip_ptr;

  cb = (control_byte*) skb_push(skb, sizeof(control_byte));
  udph = (struct udphdr*) skb_push(skb, sizeof(struct udphdr));
  memset(udph, 0, sizeof(struct udphdr));

  iph = (struct iphdr*) skb_push(skb, sizeof(struct iphdr));
  iph->ihl = 5;
  iph->version = 4;
  iph->tos = 0;
  iph->tot_len = htons(
      sizeof(struct iphdr) + sizeof(struct udphdr) + buffer_data_len(b)
          + sizeof(control_byte) + skb_iph_len);
  iph->id = 0;
  iph->frag_off = 0;
  iph->ttl = 60;
  iph->protocol = IPPROTO_UDP;
  iph->check = 0;
  iph->saddr = ipa->ifa_list->ifa_address;
  iph->daddr = b->id.ip;
  iph->check = csum((uint16_t*) iph, (iph->ihl << 2) >> 1);
  skb_set_network_header(skb, 0);

  udph->len = htons(
      sizeof(struct udphdr) + sizeof(control_byte) + skb_iph_len
          + buffer_data_len(b));
  udph->dest = b->id.port;
  udph->source = srcport;
  skb_set_transport_header(skb, sizeof(struct iphdr));

  memset(cb, 0, sizeof(control_byte));
  cb->l3_aggregated = 1;

  udph->check = 0;
  reset_buffer(b);
  return;
}

static unsigned int __push_app_packet(aggregate_buffer* b, struct sk_buff* skb,
    const struct net_device* out) {
  struct iphdr* iph = ip_hdr(skb);
  __tp(pdu)* pdu, *to_push;
  control_byte* cb;

  if (iph->protocol != IPPROTO_UDP) {
    printk(KERN_EMERG
        "Ip protocol not supported by aggregation interceptor. Cannot push application packet.\n");
    return NF_ACCEPT;
  }
  cb = control_byte_skb(skb);
  to_push = pdu_skb(skb);

  if (!cb->synched) {
    //Timestamp previous packet relative to the new one
    pdu = (__tp(pdu) *) peek_packet(b);
    if (pdu) {
      swap_pdu_byte_order(pdu);
      swap_pdu_byte_order(to_push);
      pdu->timestamp = to_push->timestamp - pdu->timestamp;
      swap_pdu_byte_order(to_push);
      swap_pdu_byte_order(pdu);
    }
  }
  pdu = to_push;

  if (buffer_data_len(b) + n_pdu_len(pdu) >= buffer_len(b)) {
    flush_buffer_app(skb, b, out);
    return NF_ACCEPT;
  }

  if (push_bytes(b, (char*) pdu, n_pdu_len(pdu))) {
    panic(
        "Called push_bytes on a buffer that has no space for them. Please verify this before asking to push bytes.");
  }

  kfree_skb(skb);
  return NF_STOLEN;
}

static unsigned int __push_ip_packet(aggregate_buffer* b, struct sk_buff* skb,
    const struct net_device* out) {
  struct iphdr* iph = ip_hdr(skb), *seeker;
  uint16_t tot_len = ntohs(iph->tot_len);
  __tp(pdu)* pdu, *to_push;
  control_byte* cb;

  if (iph->protocol != IPPROTO_UDP) {
    printk(
        "Ip protocol not supported by aggregation interceptor. Cannot push ip packet.\n");
    return NF_ACCEPT;
  }

  //Timestamp previous packet relative to the new one
  seeker = (struct iphdr *) peek_packet(b);
  if (seeker) {
    cb = (control_byte*) (((char*) seeker) + (seeker->ihl << 2)
        + sizeof(struct udphdr));

    if (!cb->synched) {
      pdu = (__tp(pdu)*) (((char*) cb) + sizeof(control_byte));
      to_push = pdu_skb(skb);

      swap_pdu_byte_order(pdu);
      swap_pdu_byte_order(to_push);
      pdu->timestamp = to_push->timestamp - pdu->timestamp;
      cb->synched = 1;
      swap_pdu_byte_order(to_push);
      swap_pdu_byte_order(pdu);
    }
  }

  if (buffer_data_len(b) + tot_len >= buffer_len(b)) {
    flush_buffer_ip(skb, b, out);
    return NF_ACCEPT;
  }

  if (push_bytes(b, (char*) iph, tot_len)) {
    panic(
        "Called push_bytes on a buffer that has no space for them. Please verify this before asking to push bytes.");
  }
  kfree_skb(skb);
  return NF_STOLEN;
}

static void init_buffers(void) {
  if (aggregate_app_packets) {
    app_buffers = make_klist();
  }
  if (aggregate_ip_packets) {
    ip_buffers = make_klist();
  }
}

static void __free_buffer(void* data) {
  free_buffer((aggregate_buffer*) data);
}

static void free_buffers(void) {
  if (aggregate_app_packets) {
    free_klist(app_buffers, __free_buffer);
  }
  if (aggregate_ip_packets) {
    free_klist(ip_buffers, __free_buffer);
  }
}

static aggregate_buffer* get_app_buffer_for(__be32 ip, __be16 port) {
  aggregate_buffer* ab = NULL;
  klist_iterator* kit = make_klist_iterator(app_buffers);
  while (klist_iterator_has_next(kit)) {
    ab = (aggregate_buffer*) (klist_iterator_next(kit))->data;
    if (ab->id.ip == ip && ab->id.port == port) {
      free_klist_iterator(kit);
      return ab;
    }
  }
  free_klist_iterator(kit);
  ab = create_aggregate_buffer(aggregate_app_packets_buffer_size, ip, port);
  add_klist_node_to_klist(app_buffers, make_klist_node(ab));
  return ab;
}

static aggregate_buffer* get_ip_buffer_for(__be32 ip, __be16 port) {
  aggregate_buffer* ab = NULL;
  klist_iterator* kit = make_klist_iterator(ip_buffers);
  while (klist_iterator_has_next(kit)) {
    ab = (aggregate_buffer*) (klist_iterator_next(kit))->data;
    if (ab->id.ip == ip && ab->id.port == port) {
      free_klist_iterator(kit);
      return ab;
    }
  }
  free_klist_iterator(kit);
  ab = create_aggregate_buffer(aggregate_ip_buffer_size, ip, port);
  add_klist_node_to_klist(ip_buffers, make_klist_node(ab));
  return ab;
}

unsigned int aggregation_post_routing_hook(filter_specs* sp,
    unsigned int hooknum, struct sk_buff* skb, const struct net_device* in,
    const struct net_device *out, int(*okfn)(struct sk_buff*)) {
  struct iphdr* iph;
  struct udphdr* udph;
  aggregate_buffer* ab;
  control_byte* cb;
  __tp(pdu)* pdu;

  if (!skb)
    return NF_ACCEPT;

  if (!skb_network_header(skb))
    return NF_ACCEPT;

  iph = ip_hdr(skb);
  switch (iph->protocol) {
  case IPPROTO_UDP:
    udph = (struct udphdr*) (((char*) iph) + (iph->ihl << 2));
    break;
  default:
    printk("Aggregation hook does not support ip protocol.\n");
    return NF_ACCEPT;
  }

  cb = control_byte_skb(skb);
  if (cb->deaggregated)
    return NF_ACCEPT;

  //Don't aggregate transport control messages
  if (!cb->app_aggregated && !cb->l3_aggregated) {
    pdu = pdu_skb(skb);
    if (pdu->flags.con_terminate || pdu->flags.oseq || pdu->flags.sack)
      return NF_ACCEPT;
  }

  ab = get_ip_buffer_for(iph->daddr, udph->dest);
  if (!ab)
    return NF_ACCEPT;
  return __push_ip_packet(ab, skb, out);
}

unsigned int aggregation_local_out_hook(filter_specs* sp, unsigned int hooknum,
    struct sk_buff* skb, const struct net_device* in,
    const struct net_device *out, int(*okfn)(struct sk_buff*)) {
  struct iphdr* iph;
  struct udphdr* udph;
  aggregate_buffer* ab;
  control_byte* cb;
  __tp(pdu)* pdu;

  if (!skb)
    return NF_ACCEPT;

  if (!skb_network_header(skb))
    return NF_ACCEPT;

  iph = ip_hdr(skb);
  switch (iph->protocol) {
  case IPPROTO_UDP:
    udph = (struct udphdr*) (((char*) iph) + (iph->ihl << 2));
    break;
  default:
    printk("Aggregation hook does not support ip protocol.\n");
    return NF_ACCEPT;
  }

  cb = control_byte_skb(skb);
  if (cb->deaggregated)
    return NF_ACCEPT;

  //Don't aggregate transport control messages
  pdu = pdu_skb(skb);
  if (pdu->flags.con_terminate || pdu->flags.oseq || pdu->flags.sack)
    return NF_ACCEPT;

  ab = get_app_buffer_for(iph->daddr, udph->dest);
  if (!ab)
    return NF_ACCEPT;
  return __push_app_packet(ab, skb, out);
}

rule* create_rule_for_specs(filter_specs* sp) {
  rule* r;
  int32_t nfilters = 0;
  filter *post_routing_filter = NULL, *local_out_filter = NULL;

  if (aggregate_app_packets)
    nfilters++;
  if (aggregate_ip_packets)
    nfilters++;

  //Sanity check!!!
  if (!nfilters) {
    printk(KERN_EMERG "Trying to register aggregation rule with no filters.\n");
    return NULL;
  }

  r = make_rule(nfilters);
  if (!r)
    return NULL;

  if (aggregate_app_packets) {
    local_out_filter = create_filter(FILTER_PRIO_FIRST, sp, r,
        FILTER_AT_LOCAL_OUT, aggregation_local_out_hook);
  }
  if (aggregate_ip_packets) {
    post_routing_filter = create_filter(FILTER_PRIO_FIRST, sp, r,
        FILTER_AT_POST_RT, aggregation_post_routing_hook);
  }

  if (aggregate_app_packets && aggregate_ip_packets) {
    (r->filters)[0] = post_routing_filter;
    (r->filters)[1] = local_out_filter;
  } else {
    if (aggregate_app_packets) {
      (r->filters)[0] = local_out_filter;
    }
    if (aggregate_ip_packets) {
      (r->filters)[0] = post_routing_filter;
    }
  }

  r->interceptor = &agg_desc;
  return r;
}

int __init init_module() {
	//Max MTU for ethernet is 1500 bytes. This code will add an mac header, ip header, udp header and a control_byte structure.
	//This means that the maximum size for payload is 1500 - sizeof(mac header) - sizeof(ip header) - sizeof (udp header) - sizeof(control byte)
	if (aggregate_app_packets_buffer_size > (1438 - sizeof(control_byte))) {
		printk(KERN_EMERG "Buffer size for aggregated packets must have a maximum of %d bytes due to maximum MTU size (1500 bytes). Given %d.\n", (1438 - sizeof(control_byte)), aggregate_app_packets_buffer_size);
		return -EINVAL;
	}

	if (aggregate_ip_buffer_size > (1438 - sizeof(control_byte))) {
		printk(KERN_EMERG "Buffer size for aggregated packets must have a maximum of %d bytes due to maximum MTU size (1500 bytes). Given %d.\n", (1438 - sizeof(control_byte)), aggregate_ip_buffer_size);
		return -EINVAL;
	}

	init_buffers();

	agg_desc.name = INTERCEPTOR_NAME;
	agg_desc.create_rule_for_specs_cb = create_rule_for_specs;

	register_interceptor(&agg_desc);

	printk(KERN_INFO "Aggregation module loaded.\n");

	return 0;
}

void __exit cleanup_module() {
	free_buffers();
	if (!unregister_interceptor(INTERCEPTOR_NAME))
	printk(
			"Unable to unregister aggregation interceptor. Interceptor framework will panic soon.\n");

	printk (KERN_INFO "Aggregation module unloaded.\n");
}

MODULE_LICENSE("GPL v2");
MODULE_AUTHOR("Frederico Gon√ßalves, [frederico.lopes.goncalves@gmail.com]");
MODULE_DESCRIPTION("Aggregation interceptor.");
